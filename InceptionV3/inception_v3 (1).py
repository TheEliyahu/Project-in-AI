# -*- coding: utf-8 -*-
"""Inception V3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kJSnge2nf2bMEhuTXe2UEidvTUcWVw7f
"""

import os
import zipfile
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model



zip_path = '/content/sample_data/Brain MRI.zip'
extract_path ='/content/sample_data/Brain_MRI'
os.makedirs(extract_path, exist_ok=True)

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)  # Extract to the corrected path
print("Dataset has been extracted succesfully")

train_dir = os.path.join(extract_path, '/content/brain_mri_dataset/Training')
test_dir = os.path.join(extract_path, '/content/brain_mri_dataset/Testing')

img_height = 224
img_width = 224
batch_size = 32

# Data Generators
datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

train_data = datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),  # Resize images to 224x224
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

val_data = datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),  # Resize images to 224x224
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

test_gen = ImageDataGenerator(rescale=1./255)
test_data = test_gen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),  # Resize images to 224x224
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Add custom classification layers
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(train_data.num_classes, activation='softmax')(x)

# Combine the base model and custom layers
model = Model(inputs=base_model.input, outputs=predictions)

# Compile the model
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

# Callbacks for training
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True
)
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,
    patience=3,
    min_lr=1e-6
)

# Train the model
history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=25,
    callbacks=[early_stopping, reduce_lr]
)

val_loss, val_accuracy = model.evaluate(val_data)

print(f"Inception Model Validation Accracy: {val_accuracy:.4f}, Loss: {val_loss:.4f}")

#Saving the Module
model.save('inception_model.h5')

test_gen = ImageDataGenerator(rescale=1./255)
test_data = test_gen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

test_loss, test_accuracy = model.evaluate(test_data)
print(f"Inception Model Test Accuracy: {test_accuracy:.4f}, Loss: {test_loss:.4f}")

# Define paths
model_path = '/content/Inception Model.h5'  # Replace with your model's path
test_dir = '/content/brain_mri_dataset/Testing'  # Replace with your testing directory path

# Load the trained model
model = load_model(model_path)
print("Model loaded successfully.")

# Preprocess the test images
test_gen = ImageDataGenerator(rescale=1./255)
test_data = test_gen.flow_from_directory(
    test_dir,
    target_size=(224, 224),  # Same size used during training
    batch_size=1,  # Process one image at a time for testing
    class_mode='categorical',
    shuffle=False  # Ensure the order matches the filenames
)

# Predict on all test images
predictions = model.predict(test_data)

# Get the class labels
class_labels = list(test_data.class_indices.keys())

# Map predictions to class labels
predicted_classes = [class_labels[np.argmax(pred)] for pred in predictions]

# Map filenames to predictions
results = list(zip(test_data.filenames, predicted_classes))

# Save results to a text file
output_file = 'test_predictions.txt'
with open(output_file, 'w') as f:
    for filename, pred_class in results:
        f.write(f"{filename}: {pred_class}\n")

print(f"Predictions saved to {output_file}")

# Optionally, print results
for filename, pred_class in results:
    print(f"Image: {filename} -> Tumor Type: {pred_class}")

from sklearn.metrics import classification_report, f1_score, confusion_matrix

train_loss = history.history['loss']
val_loss = history.history['val_loss']
train_accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
learning_rate = history.history['learning_rate']

#accuracy plot
plt.figure()
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.savefig('accuracy.png')
plt.show()

#loss plot
plt.figure()
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Training')
plt.title('Model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.savefig('loss.png')
plt.show()

#Learning Rate
plt.figure()
plt.plot(history.history['learning_rate'], label='Learning Rate')
plt.title('Model Learnig')
plt.xlabel('Epochs')
plt.ylabel('Learning Rate')
plt.legend()
plt.grid(True)
plt.savefig('learning_rate.png')
plt.show()

import seaborn as sns

# Load the saved model
model = load_model('/content/Inception Model.h5') # Load the model using load_model

# Predict on test data
predictions = model.predict(test_data)
predicted_classes = np.argmax(predictions, axis=1)  # Convert one-hot encoded predictions to class indices
true_classes = test_data.classes  # Ground truth labels
class_labels = list(test_data.class_indices.keys())  # Retrieve class label names

# ... (rest of your code)# Retrieve class label names

# Compute Weighted F1 Score
f1 = f1_score(true_classes, predicted_classes, average='weighted')
print(f"Weighted F1 Score: {f1:.4f}")

# Generate Detailed Classification Report
report = classification_report(true_classes, predicted_classes, target_names=class_labels)
print("Classification Report:")
print(report)

# Confusion Matrix
conf_matrix = confusion_matrix(true_classes, predicted_classes)

# Save metrics to a file
with open(output_metrics_file, 'w') as f:
    f.write(f"Weighted F1 Score: {f1:.4f}\n\n")
    f.write("Classification Report:\n")
    f.write(report)

print(f"Metrics saved to {output_metrics_file}")

# Visualize Confusion Matrix
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array

# Load a sample image from the dataset
sample_image_path = '' # Change to a valid image path
img = load_img(sample_image_path, target_size=(224, 224))
img_array = img_to_array(img)  # Convert image to array
img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions for augmentation

# Define the ImageDataGenerator with augmentations
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Generate augmented images
augmented_images = datagen.flow(img_array, batch_size=1)

# Number of augmentations to generate
num_augmentations = 4
plt.figure(figsize=(8, 8))

# Original Image
plt.subplot(2, 3, 1)
plt.imshow(img.astype('uint8'))  # Convert back to 8-bit for visualization
plt.title("Original Image")
plt.axis("off")

# Generate and display augmented images
for i in range(num_augmentations):
    augmented_img = next(augmented_images)[0]  # Get augmented image
    augmented_img = np.clip(augmented_img, 0, 1) * 255  # Convert back to 0-255 range
    plt.subplot(2, 3, i + 2)
    plt.imshow(augmented_img.astype('uint8'))  # Convert to 8-bit for display
    plt.title(f"Augmented {i+1}")
    plt.axis("off")

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
# Assuming model is your loaded module
predictions = model.predict(test_data)

# Convert predictions to class labels if necessary
predicted_classes = predictions.argmax(axis=1)  # For multi-class classification

# true_labels should be assigned to test_data.classes
true_labels = test_data.classes

# Compute the confusion matrix
cm = confusion_matrix(true_labels, predicted_classes)

# Get the class labels from the test data generator
class_labels = list(test_data.class_indices.keys())

# Display confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels) # Use class_labels instead of your_class_labels
disp.plot(cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.show()